{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.cp_tensor import cp_to_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "alpha = 1000  # Influence parameter\n",
    "lambda_ = 100  # Drift parameter\n",
    "sigma = 100  # Diffusion parameter\n",
    "T = 1.0  # Total time\n",
    "dt = 0.001  # Time step\n",
    "n_iterations = int(T / dt)\n",
    "\n",
    "n_particles = 1000 # initial random tensors\n",
    "I, J, K = 10, 12, 14\n",
    "rank = 5  # Rank of the decomposition\n",
    "\n",
    "# Create a random tensor\n",
    "tensor = tl.tensor(np.random.random((I, J, K)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# Step 2: Initialize particles 1000 random A, 1000 random B, 1000 random C\n",
    "\n",
    "particles = []\n",
    "for _ in range(n_particles):\n",
    "    A = np.random.randn(I, rank) # 100 10x5 matrices\n",
    "    B = np.random.randn(J, rank) # 100 12x5 matrices\n",
    "    C = np.random.randn(K, rank) # 100 14x5 matrices\n",
    "    particles.append({'A': A, 'B': B, 'C': C})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n# example indexing:\\na1_1 = particles[0]['A'][:,0]\\nb1_1 = particles[0]['B'][:,0]\\nc1_1 = particles[0]['C'][:,0]\\n\\na2_1 = particles[0]['A'][:,1]\\nb2_1 = particles[0]['B'][:,1]\\nc2_1 = particles[0]['C'][:,1]\\n\\na3_1 = particles[0]['A'][:,2]\\nb3_1 = particles[0]['B'][:,2]\\nc3_1 = particles[0]['C'][:,2]\\n\\na4_1 = particles[0]['A'][:,3]\\nb4_1 = particles[0]['B'][:,3]\\nc4_1 = particles[0]['C'][:,3]\\n\\na5_1 = particles[0]['A'][:,4]\\nb5_1 = particles[0]['B'][:,4]\\nc5_1 = particles[0]['C'][:,4]\\n\\n# ----------------------------\\n\\na1_2 = particles[1]['A'][:,0]\\nb1_2 = particles[1]['B'][:,0]\\n\\n# and so on\""
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# particles[i], where i = [A_i, B_i, C_i] and A_i.shape = 10x5, B_i.shape = 12x5, C_i.shape = 14x5\n",
    "# a{r}_{i} = particles[i-1]['A'][:,r-1]\n",
    "# where r = rank from 1 to 5, i = particles from 1 to n_particles\n",
    "\n",
    "\"\"\"\n",
    "# example indexing:\n",
    "a1_1 = particles[0]['A'][:,0]\n",
    "b1_1 = particles[0]['B'][:,0]\n",
    "c1_1 = particles[0]['C'][:,0]\n",
    "\n",
    "a2_1 = particles[0]['A'][:,1]\n",
    "b2_1 = particles[0]['B'][:,1]\n",
    "c2_1 = particles[0]['C'][:,1]\n",
    "\n",
    "a3_1 = particles[0]['A'][:,2]\n",
    "b3_1 = particles[0]['B'][:,2]\n",
    "c3_1 = particles[0]['C'][:,2]\n",
    "\n",
    "a4_1 = particles[0]['A'][:,3]\n",
    "b4_1 = particles[0]['B'][:,3]\n",
    "c4_1 = particles[0]['C'][:,3]\n",
    "\n",
    "a5_1 = particles[0]['A'][:,4]\n",
    "b5_1 = particles[0]['B'][:,4]\n",
    "c5_1 = particles[0]['C'][:,4]\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "a1_2 = particles[1]['A'][:,0]\n",
    "b1_2 = particles[1]['B'][:,0]\n",
    "\n",
    "# and so on\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "{'A': array([[ 0.33536131, -0.64027975, -0.18174423, -2.25035451,  0.47668598],\n        [-0.05126425,  0.00558905,  0.17011568,  0.11151251, -0.14152062],\n        [ 1.80658785, -0.15542475, -0.48396326,  0.64863995, -0.99937218],\n        [ 0.34086609, -0.78023415,  2.14094675, -0.68974288, -0.8184761 ],\n        [ 0.11231857,  0.32705183,  0.14677837, -0.98642057, -0.69590817],\n        [ 1.47348963,  0.00818342,  0.4790036 ,  0.98605059, -0.10170411],\n        [-1.10413498, -0.97982928, -0.70013497,  0.17535954,  0.69033585],\n        [-2.13328136,  0.99853405, -1.42756101,  0.31413716, -0.41212965],\n        [ 0.79989073,  0.53637533, -1.39071669,  1.34089937,  1.16187939],\n        [-0.20813981, -1.42928891, -0.06805849,  1.51927366,  2.26095943]]),\n 'B': array([[-0.77914331,  0.92080399, -0.5725921 ,  0.07418772,  0.06370136],\n        [-1.23836638, -0.23297674, -0.43620561,  0.72039227, -0.05083196],\n        [ 0.15849969,  0.56974778, -2.36262493,  0.27614901, -0.67312505],\n        [-2.13437223, -1.75343657,  0.29217632,  2.34075378,  1.38851557],\n        [-0.81836397, -0.46937812,  1.44641775, -0.85658141, -1.74745499],\n        [ 1.25128508, -0.64475116,  1.1248171 , -0.76838131,  1.45733778],\n        [ 0.19601314,  0.03874745, -0.1791408 , -2.11408751, -0.66470728],\n        [ 1.38239544, -0.49837208, -0.32036485, -1.08295101,  0.91790765],\n        [-0.94908768,  0.67462328,  0.29104543,  0.27285128,  1.10074128],\n        [ 0.48590752,  0.54762973,  0.0749792 , -1.96560762,  1.90437582],\n        [ 0.96345987,  0.62978333, -0.09962279,  0.9746789 , -1.75007698],\n        [ 0.91162433, -1.55224016,  0.55583907,  1.66535166,  0.92163292]]),\n 'C': array([[-1.46665315, -0.51736852, -1.22530549,  1.36952354, -1.25175188],\n        [-0.33389432,  0.46329798,  1.95209214, -1.55847053, -0.87185359],\n        [ 0.33712198, -0.97245819, -0.63119043,  2.12482121,  0.58669439],\n        [ 0.1622075 , -1.46635613,  1.71714234, -0.76139762,  1.09762472],\n        [ 0.82713037,  0.49107764,  0.30768871, -0.4876132 ,  1.37771707],\n        [-2.70868705, -0.30523356, -0.71151324,  0.45857018, -0.24117526],\n        [-0.27112178, -1.64056628,  0.16131922, -0.59735025,  2.07380081],\n        [ 0.71294371,  1.78311314,  1.54507256,  2.59454767, -0.74632049],\n        [ 0.93815181, -0.58891387,  0.06681532,  0.28080867,  0.60102472],\n        [-0.85762593, -0.65134496,  1.71586995, -0.47472096,  0.36058429],\n        [ 1.03388875, -1.78410015, -1.02462733, -0.6912845 ,  0.85013016],\n        [ 1.34724079,  0.61528443,  1.88724361, -1.82581459, -1.51540619],\n        [-3.05488007,  1.25885124,  0.0115805 , -1.07634883, -0.71624375],\n        [ 0.34058903,  1.22098961,  1.17705098,  0.37004574,  0.17196134]])}"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "def objective_function(particle):\n",
    "    # Reconstruct tensor from the given particle\n",
    "    A = particle['A']\n",
    "    B = particle['B']\n",
    "    C = particle['C']\n",
    "    reconstructed_tensor = cp_to_tensor((np.ones(rank), [A, B, C]))\n",
    "\n",
    "    # Compute the Frobenius norm of the difference\n",
    "    error = tl.norm(tensor - reconstructed_tensor)\n",
    "\n",
    "    return error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "124.05707442194252"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_function(particles[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def compute_consensus_point(particles, alpha):\n",
    "    # Find the particle with the minimum energy (V* in the image)\n",
    "    min_energy_particle = min(particles, key=objective_function)\n",
    "    min_energy = objective_function(min_energy_particle)\n",
    "\n",
    "    # Initialize the numerators and the denominator\n",
    "    numerator_A = np.zeros_like(particles[0]['A'])\n",
    "    numerator_B = np.zeros_like(particles[0]['B'])\n",
    "    numerator_C = np.zeros_like(particles[0]['C'])\n",
    "    denominator = 0.0\n",
    "\n",
    "    for particle in particles:\n",
    "        A, B, C = particle['A'], particle['B'], particle['C']\n",
    "\n",
    "        # Compute the energy for the current particle\n",
    "        energy = objective_function(particle)\n",
    "\n",
    "        # Apply the numerical stabilization trick\n",
    "        weight = np.exp(-alpha * (energy - min_energy))\n",
    "\n",
    "        # Update the numerators and the denominator\n",
    "        numerator_A += weight * A\n",
    "        numerator_B += weight * B\n",
    "        numerator_C += weight * C\n",
    "        denominator += weight\n",
    "\n",
    "    # Compute the consensus matrices (now no need for epsilon)\n",
    "    consensus_A = numerator_A / denominator\n",
    "    consensus_B = numerator_B / denominator\n",
    "    consensus_C = numerator_C / denominator\n",
    "\n",
    "    return {'A': consensus_A, 'B': consensus_B, 'C': consensus_C}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "\"def compute_consensus_point(particles, alpha):\\n    numerator_A = np.zeros_like(particles[0]['A'])\\n    numerator_B = np.zeros_like(particles[0]['B'])\\n    numerator_C = np.zeros_like(particles[0]['C'])\\n    denominator = 0.0\\n\\n    for particle in particles:\\n        A, B, C = particle['A'], particle['B'], particle['C']\\n\\n        # Compute the energy for the current particle (Frobenius norm error)\\n        energy = objective_function(particle)\\n\\n        # Compute the weight for this particle\\n        weight = np.exp(-alpha * energy)\\n\\n        # Update the numerators and the denominator\\n        numerator_A += weight * A\\n        numerator_B += weight * B\\n        numerator_C += weight * C\\n        denominator += weight\\n\\n    # Add a small epsilon to avoid division by zero\\n    epsilon = 1e-10\\n    denominator = np.maximum(denominator, epsilon)\\n\\n    # Compute the consensus matrices\\n    consensus_A = numerator_A / denominator\\n    consensus_B = numerator_B / denominator\\n    consensus_C = numerator_C / denominator\\n\\n    return {'A': consensus_A, 'B': consensus_B, 'C': consensus_C}\""
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def compute_consensus_point(particles, alpha):\n",
    "    numerator_A = np.zeros_like(particles[0]['A'])\n",
    "    numerator_B = np.zeros_like(particles[0]['B'])\n",
    "    numerator_C = np.zeros_like(particles[0]['C'])\n",
    "    denominator = 0.0\n",
    "\n",
    "    for particle in particles:\n",
    "        A, B, C = particle['A'], particle['B'], particle['C']\n",
    "\n",
    "        # Compute the energy for the current particle (Frobenius norm error)\n",
    "        energy = objective_function(particle)\n",
    "\n",
    "        # Compute the weight for this particle\n",
    "        weight = np.exp(-alpha * energy)\n",
    "\n",
    "        # Update the numerators and the denominator\n",
    "        numerator_A += weight * A\n",
    "        numerator_B += weight * B\n",
    "        numerator_C += weight * C\n",
    "        denominator += weight\n",
    "\n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    denominator = np.maximum(denominator, epsilon)\n",
    "\n",
    "    # Compute the consensus matrices\n",
    "    consensus_A = numerator_A / denominator\n",
    "    consensus_B = numerator_B / denominator\n",
    "    consensus_C = numerator_C / denominator\n",
    "\n",
    "    return {'A': consensus_A, 'B': consensus_B, 'C': consensus_C}\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "def projection_operator_matrix(V):\n",
    "    \"\"\"Apply the projection operator P(V) = I - (V ⊗ V) / |V|^2 to each column of the matrix V.\"\"\"\n",
    "    V_norm_sq = np.sum(V**2, axis=0, keepdims=True)  # Compute |V|^2 for each column (1 x n_columns)\n",
    "    outer_product = np.einsum('ik,jk->ijk', V, V)  # Compute V ⊗ V for each column (n_rows x n_rows x n_columns)\n",
    "    I = np.eye(V.shape[0])  # Identity matrix of appropriate size (n_rows x n_rows)\n",
    "    P = I[:, :, np.newaxis] - outer_product / V_norm_sq  # Apply the projection operator column-wise\n",
    "    return P"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def isotropic_update(particles, consensus_point, lambda_, sigma, dt):\n",
    "    for particle in particles:\n",
    "        \"\"\"\n",
    "        Perform isotropic updates on all particles.\n",
    "\n",
    "        Parameters:\n",
    "        - particles: list of particle dictionaries with keys 'A', 'B', 'C'.\n",
    "        - consensus_point: dictionary with keys 'A', 'B', 'C' representing the consensus matrices.\n",
    "        - lambda_: drift parameter.\n",
    "        - sigma: diffusion parameter.\n",
    "        - dt: time step.\n",
    "        \"\"\"\n",
    "\n",
    "        # Extract the matrices A, B, C from the particle and the consensus\n",
    "        A, B, C = particle['A'], particle['B'], particle['C']\n",
    "        A_consensus, B_consensus, C_consensus = consensus_point['A'], consensus_point['B'], consensus_point['C']\n",
    "\n",
    "        if objective_function(compute_consensus_point(particles, alpha)) < objective_function(particle):\n",
    "            drift_A = (-lambda_) * (A - A_consensus) * dt\n",
    "            drift_B = (-lambda_) * (B - B_consensus) * dt\n",
    "            drift_C = (-lambda_) * (C - C_consensus) * dt\n",
    "        else:\n",
    "            drift_A = np.zeros(A.shape).tolist()\n",
    "            drift_B = np.zeros(B.shape).tolist()\n",
    "            drift_C = np.zeros(C.shape).tolist()\n",
    "\n",
    "        # Isotropic noise term, applied column_wise\n",
    "        noise_A = sigma * (A - A_consensus) * np.random.randn(*A.shape) * dt\n",
    "        noise_B = sigma * (B - B_consensus) * np.random.randn(*B.shape) * dt\n",
    "        noise_C = sigma * (C - C_consensus) * np.random.randn(*C.shape) * dt\n",
    "\n",
    "        # Update particle's A, B, and C matrices\n",
    "        particle['A'] += np.array(drift_A) + np.array(noise_A)\n",
    "        particle['B'] += np.array(drift_B) + np.array(noise_B)\n",
    "        particle['C'] += np.array(drift_C) + np.array(noise_C)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "def anisotropic_update(particles, consensus_point, lambda_, sigma, dt):\n",
    "    for particle in particles:\n",
    "        # Extract the matrices A, B, C from the particle and the consensus\n",
    "        A, B, C = particle['A'], particle['B'], particle['C']\n",
    "        A_consensus, B_consensus, C_consensus = consensus_point['A'], consensus_point['B'], consensus_point['C']\n",
    "\n",
    "        # Compute the elementwise differences\n",
    "        diff_A = A - A_consensus\n",
    "        diff_B = B - B_consensus\n",
    "        diff_C = C - C_consensus\n",
    "\n",
    "        # Compute the projection terms for each matrix\n",
    "        P_A = projection_operator_matrix(A)\n",
    "        P_B = projection_operator_matrix(B)\n",
    "        P_C = projection_operator_matrix(C)\n",
    "\n",
    "        # Generate Brownian motion term\n",
    "        delta_B_A = np.random.randn(*A.shape) * np.sqrt(dt)\n",
    "        delta_B_B = np.random.randn(*B.shape) * np.sqrt(dt)\n",
    "        delta_B_C = np.random.randn(*C.shape) * np.sqrt(dt)\n",
    "\n",
    "        # Corrected drift term: includes projection P(V_ti) applied column-wis\n",
    "        drift_A = lambda_ * dt * np.einsum('ijk,jk->ik', P_A, A_consensus)\n",
    "        drift_B = lambda_ * dt * np.einsum('ijk,jk->ik', P_B, B_consensus)\n",
    "        drift_C = lambda_ * dt * np.einsum('ijk,jk->ik', P_C, C_consensus)\n",
    "\n",
    "        # Anisotropic noise term, projected and applied column-wise\n",
    "        D_A = np.diag(np.linalg.norm(diff_A, axis=0)**2)\n",
    "        noise_A = sigma * np.matmul(diff_A, D_A) * delta_B_A\n",
    "\n",
    "        D_B = np.diag(np.linalg.norm(diff_B, axis=0)**2)\n",
    "        noise_B = sigma * np.matmul(diff_B, D_B) * delta_B_B\n",
    "\n",
    "        D_C = np.diag(np.linalg.norm(diff_C, axis=0)**2)\n",
    "        noise_C = sigma * np.matmul(diff_C, D_C) * delta_B_C\n",
    "\n",
    "        # Additional correction term applied column-wise\n",
    "        correction_A = -0.5 * dt * sigma**2 * (np.linalg.norm(diff_A, axis=0, keepdims=True)**2 * A)\n",
    "        correction_B = -0.5 * dt * sigma**2 * (np.linalg.norm(diff_B, axis=0, keepdims=True)**2 * B)\n",
    "        correction_C = -0.5 * dt * sigma**2 * (np.linalg.norm(diff_C, axis=0, keepdims=True)**2 * C)\n",
    "\n",
    "        # Update particle's A, B, and C matrices\n",
    "        particle['A'] += drift_A + noise_A + correction_A\n",
    "        particle['B'] += drift_B + noise_B + correction_B\n",
    "        particle['C'] += drift_C + noise_C + correction_C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/1000, Consensus Reconstruction Error: 52.45222447596814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [105]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m     consensus_errors\u001B[38;5;241m.\u001B[39mappend(consensus_error)\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# Step 3: Update the particles\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m     \u001B[43misotropic_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparticles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsensus_point\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# or use anisotropic_update(particles, consensus_point, lambda_, sigma, dt) if desired\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# Final output: You could also save or analyze the final consensus point\u001B[39;00m\n\u001B[1;32m     24\u001B[0m final_consensus_point \u001B[38;5;241m=\u001B[39m compute_consensus_point(particles, alpha\u001B[38;5;241m=\u001B[39malpha)\n",
      "Input \u001B[0;32mIn [103]\u001B[0m, in \u001B[0;36misotropic_update\u001B[0;34m(particles, consensus_point, lambda_, sigma, dt)\u001B[0m\n\u001B[1;32m     15\u001B[0m A, B, C \u001B[38;5;241m=\u001B[39m particle[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m], particle[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m], particle[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     16\u001B[0m A_consensus, B_consensus, C_consensus \u001B[38;5;241m=\u001B[39m consensus_point[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m'\u001B[39m], consensus_point[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m], consensus_point[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m objective_function(\u001B[43mcompute_consensus_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparticles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m<\u001B[39m objective_function(particle):\n\u001B[1;32m     19\u001B[0m     drift_A \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mlambda_) \u001B[38;5;241m*\u001B[39m (A \u001B[38;5;241m-\u001B[39m A_consensus) \u001B[38;5;241m*\u001B[39m dt\n\u001B[1;32m     20\u001B[0m     drift_B \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mlambda_) \u001B[38;5;241m*\u001B[39m (B \u001B[38;5;241m-\u001B[39m B_consensus) \u001B[38;5;241m*\u001B[39m dt\n",
      "Input \u001B[0;32mIn [100]\u001B[0m, in \u001B[0;36mcompute_consensus_point\u001B[0;34m(particles, alpha)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_consensus_point\u001B[39m(particles, alpha):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# Find the particle with the minimum energy (V* in the image)\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     min_energy_particle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mmin\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparticles\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobjective_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m     min_energy \u001B[38;5;241m=\u001B[39m objective_function(min_energy_particle)\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;66;03m# Initialize the numerators and the denominator\u001B[39;00m\n",
      "Input \u001B[0;32mIn [98]\u001B[0m, in \u001B[0;36mobjective_function\u001B[0;34m(particle)\u001B[0m\n\u001B[1;32m      4\u001B[0m B \u001B[38;5;241m=\u001B[39m particle[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mB\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      5\u001B[0m C \u001B[38;5;241m=\u001B[39m particle[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m reconstructed_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mcp_to_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrank\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mB\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mC\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Compute the Frobenius norm of the difference\u001B[39;00m\n\u001B[1;32m      9\u001B[0m error \u001B[38;5;241m=\u001B[39m tl\u001B[38;5;241m.\u001B[39mnorm(tensor \u001B[38;5;241m-\u001B[39m reconstructed_tensor)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorly/cp_tensor.py:486\u001B[0m, in \u001B[0;36mcp_to_tensor\u001B[0;34m(cp_tensor, mask)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    482\u001B[0m     full_tensor \u001B[38;5;241m=\u001B[39m T\u001B[38;5;241m.\u001B[39msum(\n\u001B[1;32m    483\u001B[0m         khatri_rao([factors[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m weights] \u001B[38;5;241m+\u001B[39m factors[\u001B[38;5;241m1\u001B[39m:], mask\u001B[38;5;241m=\u001B[39mmask), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    484\u001B[0m     )\n\u001B[0;32m--> 486\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfull_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorly/base.py:79\u001B[0m, in \u001B[0;36mfold\u001B[0;34m(unfolded_tensor, mode, shape)\u001B[0m\n\u001B[1;32m     77\u001B[0m mode_dim \u001B[38;5;241m=\u001B[39m full_shape\u001B[38;5;241m.\u001B[39mpop(mode)\n\u001B[1;32m     78\u001B[0m full_shape\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, mode_dim)\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmoveaxis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43munfolded_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_shape\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorly/backend/__init__.py:206\u001B[0m, in \u001B[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_backend_method\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;124;03m\"\"\"A dynamically dispatched method\u001B[39;00m\n\u001B[1;32m    204\u001B[0m \n\u001B[1;32m    205\u001B[0m \u001B[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001B[39;00m\n\u001B[0;32m--> 206\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_THREAD_LOCAL_DATA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__dict__\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbackend\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\n\u001B[1;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mmoveaxis\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/core/numeric.py:1460\u001B[0m, in \u001B[0;36mmoveaxis\u001B[0;34m(a, source, destination)\u001B[0m\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(source) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(destination):\n\u001B[1;32m   1457\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`source` and `destination` arguments must have \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   1458\u001B[0m                      \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthe same number of elements\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 1460\u001B[0m order \u001B[38;5;241m=\u001B[39m [n \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m source]\n\u001B[1;32m   1462\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dest, src \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mzip\u001B[39m(destination, source)):\n\u001B[1;32m   1463\u001B[0m     order\u001B[38;5;241m.\u001B[39minsert(dest, src)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# List to store reconstruction errors of the consensus point at each iteration\n",
    "consensus_errors = []\n",
    "\n",
    "# Main iteration loop\n",
    "for iteration in range(n_iterations):\n",
    "    # Step 1: Calculate the consensus point\n",
    "    consensus_point = compute_consensus_point(particles, alpha=alpha)\n",
    "\n",
    "    # Step 2: Compute the reconstruction error for the consensus point\n",
    "    consensus_tensor = cp_to_tensor((np.ones(rank), [consensus_point['A'], consensus_point['B'], consensus_point['C']]))\n",
    "    consensus_error = tl.norm(tensor - consensus_tensor)\n",
    "\n",
    "    # Print the reconstruction error of the consensus point\n",
    "    print(f\"Iteration {iteration + 1}/{n_iterations}, Consensus Reconstruction Error: {consensus_error}\")\n",
    "\n",
    "    # Store the error for later plotting\n",
    "    consensus_errors.append(consensus_error)\n",
    "\n",
    "    # Step 3: Update the particles\n",
    "    isotropic_update(particles, consensus_point, lambda_, sigma, dt)\n",
    "    # or use anisotropic_update(particles, consensus_point, lambda_, sigma, dt) if desired\n",
    "\n",
    "# Final output: You could also save or analyze the final consensus point\n",
    "final_consensus_point = compute_consensus_point(particles, alpha=alpha)\n",
    "final_consensus_tensor = cp_to_tensor((np.ones(rank), [final_consensus_point['A'], final_consensus_point['B'], final_consensus_point['C']]))\n",
    "final_error = tl.norm(tensor - final_consensus_tensor)\n",
    "\n",
    "print(\"Final Consensus Reconstruction Error: \", final_error)\n",
    "\n",
    "# Plotting the consensus reconstruction errors over iterations\n",
    "plt.plot(consensus_errors, label='Consensus Reconstruction Error')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error of Consensus Point Over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
