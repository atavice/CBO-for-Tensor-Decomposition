{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with dt=0.01, nu=5000, lambda=1.5, sigma=8.5, K=1000, eta=0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": "     dt    nu  lambda  sigma   eta     K  consensus_abs_error  \\\n0  0.01  5000     1.5    8.5  0.85  1000             6.024777   \n\n   consensus_rel_error  \n0             0.456325  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dt</th>\n      <th>nu</th>\n      <th>lambda</th>\n      <th>sigma</th>\n      <th>eta</th>\n      <th>K</th>\n      <th>consensus_abs_error</th>\n      <th>consensus_rel_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>5000</td>\n      <td>1.5</td>\n      <td>8.5</td>\n      <td>0.85</td>\n      <td>1000</td>\n      <td>6.024777</td>\n      <td>0.456325</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorly as tl\n",
    "from tensorly.cp_tensor import cp_to_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "\n",
    "I, J, K_tensor = 8, 8, 8\n",
    "rank = 3\n",
    "tensor = tl.tensor(np.random.uniform(0, 1, (I, J, K_tensor)))\n",
    "\n",
    "alpha_0 = 1e3\n",
    "alpha_final = 1e15\n",
    "\n",
    "dt_list = [0.01]\n",
    "nu_list = [5000]\n",
    "lambda_sigma_list = [(1.5, 8.5)]\n",
    "K_list = [1000]\n",
    "eta_list = [0.85]\n",
    "\n",
    "param_grid = list(itertools.product(dt_list, nu_list, lambda_sigma_list, K_list, eta_list))\n",
    "\n",
    "def alpha_sequence(alpha_0, alpha_K, K):\n",
    "    ks = np.arange(K+1)\n",
    "    alphas = alpha_0 + (ks / K) * (alpha_K - alpha_0)\n",
    "    return alphas\n",
    "\n",
    "def objective_function(particle, tensor, rank):\n",
    "    A = particle['A']\n",
    "    B = particle['B']\n",
    "    C = particle['C']\n",
    "    reconstructed_tensor = cp_to_tensor((np.ones(rank), [A, B, C]))\n",
    "    error = tl.norm(tensor - reconstructed_tensor)\n",
    "    return error\n",
    "\n",
    "def compute_consensus_point(particles, alpha, tensor, rank):\n",
    "    min_energy_particle = min(particles, key=lambda p: objective_function(p, tensor, rank))\n",
    "    min_energy = objective_function(min_energy_particle, tensor, rank)\n",
    "\n",
    "    numerator_A = np.zeros_like(particles[0]['A'])\n",
    "    numerator_B = np.zeros_like(particles[0]['B'])\n",
    "    numerator_C = np.zeros_like(particles[0]['C'])\n",
    "    denominator = 0.0\n",
    "\n",
    "    for particle in particles:\n",
    "        energy = objective_function(particle, tensor, rank)\n",
    "        weight = np.exp(-alpha * (energy - min_energy))\n",
    "        numerator_A += weight * particle['A']\n",
    "        numerator_B += weight * particle['B']\n",
    "        numerator_C += weight * particle['C']\n",
    "        denominator += weight\n",
    "\n",
    "    consensus_A = numerator_A / denominator\n",
    "    consensus_B = numerator_B / denominator\n",
    "    consensus_C = numerator_C / denominator\n",
    "    return {'A': consensus_A, 'B': consensus_B, 'C': consensus_C}\n",
    "\n",
    "def project_matrices_to_ball(particles, consensus_point, eta):\n",
    "    for particle in particles:\n",
    "        for key in ['A', 'B', 'C']:\n",
    "            vec_particle = particle[key].flatten()\n",
    "            vec_consensus = consensus_point[key].flatten()\n",
    "            distance = np.linalg.norm(vec_particle - vec_consensus)\n",
    "            radius = eta * distance\n",
    "            if distance > radius:\n",
    "                direction = (vec_particle - vec_consensus) / distance\n",
    "                vec_particle = vec_consensus + radius * direction\n",
    "            particle[key] = vec_particle.reshape(particle[key].shape)\n",
    "    return particles\n",
    "\n",
    "def anisotropic_update(particles, consensus_point, lambda_, sigma, dt, tensor, rank):\n",
    "    consensus_point_loss = objective_function(consensus_point, tensor, rank)\n",
    "    for particle in particles:\n",
    "        A, B, C = particle['A'], particle['B'], particle['C']\n",
    "        A_consensus, B_consensus, C_consensus = consensus_point['A'], consensus_point['B'], consensus_point['C']\n",
    "\n",
    "        current_loss = objective_function(particle, tensor, rank)\n",
    "        if consensus_point_loss < current_loss:\n",
    "            drift_A = (-lambda_) * (A - A_consensus) * dt\n",
    "            drift_B = (-lambda_) * (B - B_consensus) * dt\n",
    "            drift_C = (-lambda_) * (C - C_consensus) * dt\n",
    "        else:\n",
    "            drift_A = np.zeros_like(A)\n",
    "            drift_B = np.zeros_like(B)\n",
    "            drift_C = np.zeros_like(C)\n",
    "\n",
    "        # Normal distribution noise\n",
    "        B_A = np.random.normal(loc=0, scale=1, size=A.shape)\n",
    "        B_B = np.random.normal(loc=0, scale=1, size=B.shape)\n",
    "        B_C = np.random.normal(loc=0, scale=1, size=C.shape)\n",
    "\n",
    "        diffusion_A = sigma * (A - A_consensus) * B_A * np.sqrt(dt)\n",
    "        diffusion_B = sigma * (B - B_consensus) * B_B * np.sqrt(dt)\n",
    "        diffusion_C = sigma * (C - C_consensus) * B_C * np.sqrt(dt)\n",
    "\n",
    "        particle['A'] += drift_A + diffusion_A\n",
    "        particle['B'] += drift_B + diffusion_B\n",
    "        particle['C'] += drift_C + diffusion_C\n",
    "\n",
    "    return particles\n",
    "\n",
    "def resample_particles(particles, consensus_point, noise_scale=0.01):\n",
    "    \"\"\"\n",
    "    Resample each particle's matrices A, B, C around the consensus point.\n",
    "    noise_scale controls the standard deviation of the Gaussian noise.\n",
    "    \"\"\"\n",
    "    for particle in particles:\n",
    "        for key in ['A', 'B', 'C']:\n",
    "            shape = consensus_point[key].shape\n",
    "            # Replace the particle matrix with consensus + small noise\n",
    "            noise = np.random.normal(loc=0.0, scale=noise_scale, size=shape)\n",
    "            noise = np.clip(noise, -0.05, 0.05)\n",
    "\n",
    "            particle[key] = consensus_point[key] + noise\n",
    "    return particles\n",
    "\n",
    "results = []\n",
    "\n",
    "for dt, nu, (lambda_, sigma), K, eta in param_grid:\n",
    "    print(f\"Running with dt={dt}, nu={nu}, lambda={lambda_}, sigma={sigma}, K={K}, eta={eta}\")\n",
    "\n",
    "    particles = []\n",
    "    for _ in range(nu):\n",
    "        A = np.random.uniform(0, 1, (I, rank))\n",
    "        B = np.random.uniform(0, 1, (J, rank))\n",
    "        C = np.random.uniform(0, 1, (K_tensor, rank))\n",
    "        particles.append({'A': A, 'B': B, 'C': C})\n",
    "\n",
    "    alpha_values = alpha_sequence(alpha_0, alpha_final, K)\n",
    "\n",
    "    for iteration in range(K + 1):\n",
    "        alpha_current = alpha_values[iteration]\n",
    "\n",
    "        # Compute consensus point\n",
    "        consensus_point = compute_consensus_point(particles, alpha_current, tensor, rank)\n",
    "        consensus_tensor = cp_to_tensor((np.ones(rank),\n",
    "                                         [consensus_point['A'],\n",
    "                                          consensus_point['B'],\n",
    "                                          consensus_point['C']]))\n",
    "\n",
    "        consensus_abs_error = tl.norm(tensor - consensus_tensor)\n",
    "        nonzero_mask = tensor != 0\n",
    "        consensus_rel_error = (\n",
    "            tl.norm(tensor[nonzero_mask] - consensus_tensor[nonzero_mask]) /\n",
    "            tl.norm(tensor[nonzero_mask])\n",
    "        )\n",
    "\n",
    "        if iteration < K:\n",
    "            # 1) Apply drift-diffusion\n",
    "            particles = anisotropic_update(\n",
    "                particles, consensus_point,\n",
    "                lambda_=lambda_, sigma=sigma,\n",
    "                dt=dt, tensor=tensor, rank=rank\n",
    "            )\n",
    "            # 2) (Optional) Project to the shrinking ball\n",
    "            particles = project_matrices_to_ball(particles, consensus_point, eta)\n",
    "            # 3) Resample around consensus to maintain diversity\n",
    "            particles = resample_particles(particles, consensus_point, noise_scale=0.01)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'dt': dt,\n",
    "        'nu': nu,\n",
    "        'lambda': lambda_,\n",
    "        'sigma': sigma,\n",
    "        'eta': eta,\n",
    "        'K': K,\n",
    "        'consensus_abs_error': consensus_abs_error,\n",
    "        'consensus_rel_error': consensus_rel_error\n",
    "    })\n",
    "\n",
    "df_results_with_heurs = pd.DataFrame(results)\n",
    "df_results_with_heurs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
